import logging
import requests
import json
import time
import threading
import schedule
import torch
import torch.nn as nn
import torch.optim as optim
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters
from datetime import datetime, timedelta
import asyncio  # –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è v21

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

# –ö–ª—é—á–∏ (–∏–∑ env vars)
TELEGRAM_TOKEN = 'YOUR_TELEGRAM_BOT_TOKEN_HERE'  # Render –ø–æ–¥—Å—Ç–∞–≤–∏—Ç –∏–∑ env
MORALIS_API_KEY = 'YOUR_MORALIS_API_KEY_HERE'

# –§–∞–π–ª—ã –¥–ª—è persistence
SUBSCRIBERS_FILE = 'subscribers.txt'
HISTORICAL_FILE = 'historical_tokens.json'

# ML –º–æ–¥–µ–ª—å: –ü—Ä–æ—Å—Ç–∞—è NN –¥–ª—è scoring (features: liquidity, holders, price_change)
class TokenScorer(nn.Module):
    def __init__(self):
        super(TokenScorer, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(3, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()  # Score 0-1
        )
    
    def forward(self, x):
        return self.fc(x)

model = TokenScorer()
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.BCELoss()

# –ó–∞–≥—Ä—É–∑–∫–∞/—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –º–æ–¥–µ–ª–∏
def load_historical():
    try:
        with open(HISTORICAL_FILE, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        return []

def save_historical(data):
    with open(HISTORICAL_FILE, 'w') as f:
        json.dump(data, f)

# –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º labels: 1 –µ—Å–ª–∏ price_change > 10%, else 0)
def train_model():
    historical = load_historical()
    if len(historical) < 10:
        logger.info("Not enough data for training.")
        return
    
    features = []
    labels = []
    for token in historical:
        liq = float(token.get('usd_liquidity', 0))
        holders = token.get('holders_count', 0)
        change = float(token.get('price_change', 0))
        features.append([liq, holders, change])
        labels.append(1 if change > 0.1 else 0)  # –ü—Ä–∏–º–µ—Ä: >10% —Ä–æ—Å—Ç = —Ç–æ–ø
    
    X = torch.tensor(features, dtype=torch.float32)
    y = torch.tensor(labels, dtype=torch.float32).unsqueeze(1)
    
    for epoch in range(100):
        optimizer.zero_grad()
        outputs = model(X)
        loss = criterion(outputs, y)
        loss.backward()
        optimizer.step()
    
    logger.info("Model trained.")

# Score —Ç–æ–∫–µ–Ω–∞ —Å ML
def get_ml_score(token):
    liq = float(token.get('usd_liquidity', 0))
    holders = token.get('holders_count', 0)
    change = float(token.get('price_change', 0))
    input_tensor = torch.tensor([[liq, holders, change]], dtype=torch.float32)
    with torch.no_grad():
        score = model(input_tensor).item()
    return score

# –ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ —Å pump.fun
def get_new_pumpfun_tokens(limit=10):
    url = f"https://solana-gateway.moralis.io/token/mainnet/exchange/pumpfun/new?limit={limit}"
    headers = {"X-API-Key": MORALIS_API_KEY}
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        return response.json()
    else:
        logger.error(f"Error: {response.text}")
        return []

# –ü–æ–ª—É—á–µ–Ω–∏–µ metadata –∏ security –¥–ª—è —Ç–æ–∫–µ–Ω–∞
def get_token_metadata(address):
    url = f"https://solana-gateway.moralis.io/token/mainnet/{address}"
    headers = {"X-API-Key": MORALIS_API_KEY}
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        return response.json()
    return None

# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Ç–æ–ø–∞ (security + ML score)
def is_potential_top_token(token_data, metadata):
    security = metadata.get('security', {})
    if (
        not security.get('is_honeypot', False) and
        float(security.get('buy_tax', 0)) < 0.1 and
        float(security.get('sell_tax', 0)) < 0.1 and
        not security.get('cannot_sell_all', False) and
        security.get('is_open_source', True)
    ):
        score = get_ml_score(token_data)
        return score > 0.7  # ML-—Ñ–∏–ª—å—Ç—Ä
    return False

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞
def find_tokens():
    tokens = get_new_pumpfun_tokens(limit=20)  # –ë–æ–ª—å—à–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞
    historical = load_historical()
    new_historical = historical.copy()
    filtered = []
    
    for token in tokens:
        address = token['address']
        metadata = get_token_metadata(address)
        if metadata and is_potential_top_token(token, metadata):
            filtered.append((token, metadata))
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ historical –¥–ª—è ML
        if address not in [t.get('address', '') for t in historical]:
            new_historical.append(token)  # –î–æ–±–∞–≤–ª—è–µ–º price_change etc. later if needed
    
    save_historical(new_historical[:500])  # Limit history
    return filtered

# –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
def format_tokens(filtered):
    message = "–¢–æ–ø —Å–≤–µ–∂–∏–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –º–µ–º–∫–æ–∏–Ω—ã –Ω–∞ pump.fun (–æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã –æ—Ç —Å–∫–∞–º–∞):\n\n"
    for token, metadata in filtered[:10]:
        name = token.get('name', 'Unknown')
        symbol = token.get('symbol', 'N/A')
        price = token.get('usd_price', 'N/A')
        created = token.get('created_timestamp', 'N/A')
        address = token['address']
        message += f"üìà {name} ({symbol})\n–¶–µ–Ω–∞: ${price}\n–°–æ–∑–¥–∞–Ω: {created}\n–ê–¥—Ä–µ—Å: {address}\nDexScreener: https://dexscreener.com/solana/{address}\n\n"
    return message if filtered else "–ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤ —Å–µ–π—á–∞—Å."

# –ö–æ–º–∞–Ω–¥–∞ /start
async def start(update: Update, context):
    await update.message.reply_text('–ü—Ä–∏–≤–µ—Ç! –ë–æ—Ç –¥–ª—è —Å–≤–µ–∂–∏—Ö –º–µ–º–∫–æ–∏–Ω–æ–≤ –Ω–∞ pump.fun. /find - –ø–æ–∏—Å–∫, /subscribe - —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è.')

# –ö–æ–º–∞–Ω–¥–∞ /find
async def find(update: Update, context):
    filtered = find_tokens()
    message = format_tokens(filtered)
    await update.message.reply_text(message)

# –ü–æ–¥–ø–∏—Å–∫–∞ /subscribe
async def subscribe(update: Update, context):
    chat_id = update.message.chat_id
    subscribers = load_subscribers()
    if chat_id not in subscribers:
        subscribers.append(chat_id)
        save_subscribers(subscribers)
        await update.message.reply_text('–í—ã –ø–æ–¥–ø–∏—Å–∞–Ω—ã –Ω–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ –Ω–æ–≤—ã—Ö —Ç–æ–ø–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–∞—Ö!')
    else:
        await update.message.reply_text('–í—ã —É–∂–µ –ø–æ–¥–ø–∏—Å–∞–Ω—ã.')

# –ó–∞–≥—Ä—É–∑–∫–∞/—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤
def load_subscribers():
    try:
        with open(SUBSCRIBERS_FILE, 'r') as f:
            return [int(line.strip()) for line in f]
    except FileNotFoundError:
        return []

def save_subscribers(subs):
    with open(SUBSCRIBERS_FILE, 'w') as f:
        for s in subs:
            f.write(f"{s}\n")

# –§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤—ã—Ö –∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
last_check = datetime.now() - timedelta(minutes=5)
def check_and_notify(application):
    global last_check
    filtered = find_tokens()
    recent_filtered = [t for t in filtered if datetime.fromtimestamp(t[0].get('created_timestamp', 0)/1000) > last_check]
    
    if recent_filtered:
        message = "–ù–æ–≤—ã–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–ø—ã –Ω–∞ pump.fun:\n\n" + format_tokens([list(t) for t in recent_filtered])  # –ê–¥–∞–ø—Ç–∞—Ü–∏—è –¥–ª—è list/tuple
        subscribers = load_subscribers()
        for chat_id in subscribers:
            try:
                asyncio.run_coroutine_threadsafe(application.bot.send_message(chat_id=chat_id, text=message), application.loop)
            except Exception as e:
                logger.error(f"Error sending to {chat_id}: {e}")
    
    last_check = datetime.now()

# Schedule –∑–∞–¥–∞—á–∏ (–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è v21)
def run_schedule(application):
    schedule.every(5).minutes.do(check_and_notify, application=application)
    schedule.every(30).minutes.do(train_model)
    
    while True:
        schedule.run_pending()
        time.sleep(1)

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è (–æ–±–Ω–æ–≤–ª–µ–Ω–æ –¥–ª—è v21: –±–µ–∑ Updater)
def main():
    global TELEGRAM_TOKEN, MORALIS_API_KEY  # –î–ª—è env vars
    # –ü–æ–¥—Å—Ç–∞–≤–ª—è–µ–º env vars (Render –∏—Ö —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç)
    import os
    TELEGRAM_TOKEN = os.getenv('TELEGRAM_TOKEN', TELEGRAM_TOKEN)
    MORALIS_API_KEY = os.getenv('MORALIS_API_KEY', MORALIS_API_KEY)
    
    if 'YOUR_' in TELEGRAM_TOKEN:
        logger.error("TELEGRAM_TOKEN not set!")
        return
    
    application = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("find", find))
    application.add_handler(CommandHandler("subscribe", subscribe))
    
    # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, lambda update, context: update.message.reply_text('–ò—Å–ø–æ–ª—å–∑—É–π /find –∏–ª–∏ /subscribe.')))
    
    # –ó–∞–ø—É—Å–∫ schedule –≤ —Ñ–æ–Ω–µ
    threading.Thread(target=run_schedule, args=(application,), daemon=True).start()
    
    # –ù–∞—á–∞–ª—å–Ω–∞—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞
    train_model()
    
    # –ó–∞–ø—É—Å–∫ polling (v21 —Å—Ç–∏–ª—å)
    logger.info("Bot started")
    application.run_polling()

if __name__ == '__main__':
    main()
